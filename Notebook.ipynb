{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OilyGiant Mining Company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In today's dynamic and competitive oil industry, the ability to strategically locate and develop new oil wells is crucial for companies like OilyGiant Mining Company to maximize profitability and ensure sustainable operations. The success of such endeavors heavily relies on the careful analysis of oil well characteristics, including oil quality and reserve volumes, within different geographic regions. By leveraging advanced predictive modeling techniques, such as machine learning, we can accurately estimate reserve volumes for potential new wells and identify promising locations for drilling. This project aims to utilize oil sample data from three distinct regions, coupled with known well parameters, to develop a robust model that not only pinpoints the region with the highest potential profit margin but also assesses associated risks using innovative methodologies like Bootstrapping. Ultimately, this research will provide valuable insights and actionable recommendations to guide decision-making in selecting the optimal site for a new oil well, contributing to the continued success and growth of OilyGiant Mining Company in the oil exploration and production sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import math\n",
    "from scipy import stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data was sucessfully loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    reg_data_0 = pd.read_csv(\"/datasets/geo_data_0.csv\")\n",
    "    reg_data_1 = pd.read_csv(\"/datasets/geo_data_1.csv\")\n",
    "    reg_data_2 = pd.read_csv(\"/datasets/geo_data_2.csv\")\n",
    "except FileNotFoundError as f_error:\n",
    "    print(f\"The following error: ({f_error}) occured while loading datasets\")\n",
    "else:\n",
    "    print(\"The data was sucessfully loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iJLyR</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>2.978566</td>\n",
       "      <td>168.620776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xdl7t</td>\n",
       "      <td>1.988431</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>154.036647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wX4Hy</td>\n",
       "      <td>0.969570</td>\n",
       "      <td>0.489775</td>\n",
       "      <td>-0.735383</td>\n",
       "      <td>64.741541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tL6pL</td>\n",
       "      <td>0.645075</td>\n",
       "      <td>0.530656</td>\n",
       "      <td>1.780266</td>\n",
       "      <td>49.055285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BYPU6</td>\n",
       "      <td>-0.400648</td>\n",
       "      <td>0.808337</td>\n",
       "      <td>-5.624670</td>\n",
       "      <td>72.943292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>j9Oui</td>\n",
       "      <td>0.643105</td>\n",
       "      <td>-0.551583</td>\n",
       "      <td>2.372141</td>\n",
       "      <td>113.356160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLuZU</td>\n",
       "      <td>2.173381</td>\n",
       "      <td>0.563698</td>\n",
       "      <td>9.441852</td>\n",
       "      <td>127.910945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
       "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
       "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
       "5  wX4Hy  0.969570  0.489775 -0.735383   64.741541\n",
       "6  tL6pL  0.645075  0.530656  1.780266   49.055285\n",
       "7  BYPU6 -0.400648  0.808337 -5.624670   72.943292\n",
       "8  j9Oui  0.643105 -0.551583  2.372141  113.356160\n",
       "9  OLuZU  2.173381  0.563698  9.441852  127.910945"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take initial look at data\n",
    "\n",
    "reg_data_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg 0 Shape: (100000, 5)\n",
      "Reg 1 Shape: (100000, 5)\n",
      "Reg 2 Shape: (100000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Observe shape of data\n",
    "\n",
    "print(f\"Reg 0 Shape: {reg_data_0.shape}\")\n",
    "print(f\"Reg 1 Shape: {reg_data_1.shape}\")\n",
    "print(f\"Reg 2 Shape: {reg_data_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Data 0:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "\n",
      "\n",
      "Region Data 1:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "\n",
      "\n",
      "Region Data 2:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at general info for each data set\n",
    "\n",
    "datasets_i = (reg_data_0, reg_data_1, reg_data_2)\n",
    "\n",
    "for i in range(len(datasets_i)):\n",
    "    print(f\"Region Data {i}:\")\n",
    "    datasets_i[i].info()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in Region Data 0: 10\n",
      "Number of duplicates in Region Data 1: 4\n",
      "Number of duplicates in Region Data 2: 4\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in ID column\n",
    "\n",
    "for i in range(len(datasets_i)):\n",
    "    print(f\"Number of duplicates in Region Data {i}: {datasets_i[i]['id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The datasets `reg_data_0`, `reg_data_1`, and `reg_data_2` are identical in structure (shape), each containing no missing values and comprising 5 columns with consistent data types:\n",
    "- id: Object-type\n",
    "- f0: float64\n",
    "- f1: float64\n",
    "- f2: float64\n",
    "- product: float64\n",
    "\n",
    "Duplicate values are present in the `id` column across all three datasets. Given that these columns are unnecessary for the model, they can be safely removed. There are no duplicates in any other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column for model\n",
    "\n",
    "reg_data_0 = reg_data_0.drop(columns='id')\n",
    "reg_data_1 = reg_data_1.drop(columns='id')\n",
    "reg_data_2 = reg_data_2.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign back to datasets list\n",
    "\n",
    "datasets_f = (reg_data_0, reg_data_1, reg_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Summary:\n",
    "Each file corresponds to data from three distinct regions.\n",
    "\n",
    "- `id` -- a unique identifier for each oil well, has been removed as it does not contribute to model training.\n",
    "- `f0`, `f1`, `f2` -- represent various features of the oil wells and have consistent scaling.\n",
    "- `product` -- indicates the volume of reserves in each oil well (measured in thousand barrels).\n",
    "\n",
    "All files are now clear of duplicate entries and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_3_1(dataset, drop_cols, target_col, test_s=0.25, rnd_state=123, shuffle=True, axis=1):\n",
    "    '''Prints a statement specifying the data-split used and returns 2 variables (features and target) for the train and validation datasets respectively'''\n",
    "    \n",
    "    # Define the features & target\n",
    "    features = dataset.drop(drop_cols, axis=axis)\n",
    "    target = dataset[target_col]\n",
    "    \n",
    "    # Split the source data into 25% for Validation and 75% for Training\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=test_s, shuffle=True, random_state=rnd_state)\n",
    "    \n",
    "    # Print confirmation of data split\n",
    "    sum_of_datasets = len(features_train) + len(features_valid) \n",
    "    if len(dataset) == sum_of_datasets:\n",
    "        print(f\"Features split ratio is 3:1, where data split is allocated as:\\n- Training = 75% [shape={features_train.shape}]\\n- Validation = 25% [shape={features_valid.shape}]\")\n",
    "        print(f\"Target split ratio is 3:1, where data split is allocated as:\\n- Training = 75% [shape={target_train.shape}]\\n- Validation = 25% [shape={target_valid.shape}]\")\n",
    "    \n",
    "    return features_train, features_valid, target_train, target_valid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg 0:\n",
      "Features split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000, 3)]\n",
      "- Validation = 25% [shape=(25000, 3)]\n",
      "Target split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000,)]\n",
      "- Validation = 25% [shape=(25000,)]\n",
      "\n",
      "Reg 1:\n",
      "Features split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000, 3)]\n",
      "- Validation = 25% [shape=(25000, 3)]\n",
      "Target split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000,)]\n",
      "- Validation = 25% [shape=(25000,)]\n",
      "\n",
      "Reg 2:\n",
      "Features split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000, 3)]\n",
      "- Validation = 25% [shape=(25000, 3)]\n",
      "Target split ratio is 3:1, where data split is allocated as:\n",
      "- Training = 75% [shape=(75000,)]\n",
      "- Validation = 25% [shape=(25000,)]\n"
     ]
    }
   ],
   "source": [
    "# Define features & target for all three regions\n",
    "\n",
    "print(\"Reg 0:\")\n",
    "features_0_train, features_0_valid, target_0_train, target_0_valid = split_data_3_1(reg_data_0, ['product'], 'product')\n",
    "print()\n",
    "\n",
    "print(\"Reg 1:\")\n",
    "features_1_train, features_1_valid, target_1_train, target_1_valid = split_data_3_1(reg_data_1, ['product'], 'product')\n",
    "print()\n",
    "\n",
    "print(\"Reg 2:\")\n",
    "features_2_train, features_2_valid, target_2_train, target_2_valid = split_data_3_1(reg_data_2, ['product'], 'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics\n",
    "\n",
    "def calculate_regression_metrics(x, y):\n",
    "    '''Accepts the target and predicted values and resturns several metrics'''\n",
    "    mse = mean_squared_error(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared=False)\n",
    "    r2 = r2_score(x, y)\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    \n",
    "    print(f\"MSE: {mse}\\nRMSE: {rmse}\\nR^2: {r2}\\nMAE: {mae}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region 0 Model\n",
    "\n",
    "model_0 = LinearRegression()\n",
    "model_0.fit(features_0_train, target_0_train)\n",
    "predictions_0_valid = model_0.predict(features_0_valid)\n",
    "\n",
    "# Store values as a list\n",
    "correct_values_0 = target_0_valid.tolist()\n",
    "predicted_values_0 = predictions_0_valid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Region 0:\n",
      "MSE: 1417.3615751967832\n",
      "RMSE: 37.64786282376176\n",
      "R^2: 0.2812975228159569\n",
      "MAE: 30.984212391272273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Metrics for Region 0\n",
    "\n",
    "print(\"Metrics for Region 0:\")\n",
    "calculate_regression_metrics(target_0_valid, predictions_0_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region 1 Model\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(features_1_train, target_1_train)\n",
    "predictions_1_valid = model_1.predict(features_1_valid)\n",
    "\n",
    "# Store values as a list\n",
    "correct_values_1 = target_1_valid.tolist()\n",
    "predicted_values_1 = predictions_1_valid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Region 1:\n",
      "MSE: 0.8017661964648819\n",
      "RMSE: 0.8954139804944313\n",
      "R^2: 0.9996180923165817\n",
      "MAE: 0.7210648408937341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Metrics for Region 1\n",
    "\n",
    "print(\"Metrics for Region 1:\")\n",
    "calculate_regression_metrics(target_1_valid, predictions_1_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region 2 Model\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(features_2_train, target_2_train)\n",
    "predictions_2_valid = model_2.predict(features_2_valid)\n",
    "\n",
    "# Store values as a list\n",
    "correct_values_2 = target_2_valid.tolist()\n",
    "predicted_values_2 = predictions_2_valid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Region 2:\n",
      "MSE: 1610.2587969766078\n",
      "RMSE: 40.12803006598514\n",
      "R^2: 0.19313657905573023\n",
      "MAE: 32.80763017044863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Metrics for Region 2\n",
    "\n",
    "print(\"Metrics for Region 2:\")\n",
    "calculate_regression_metrics(target_2_valid, predictions_2_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* The data indicates that Region 2 has the highest average reserve, followed by Region 0, and then Region 1 with the lowest.\n",
    "\n",
    "* Based on the Root Mean Squared Error (RMSE) metric, the RMSE value for Region 1 is notably lower than that for Region 0 or Region 2. This suggests that the model performed most accurately in Region 1 in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Profit Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for total budget\n",
    "TOTAL_BUDGET = 100000000\n",
    "\n",
    "# Variable for revenue per unit\n",
    "REVENUE_PER_UNIT = 4.5 * 1000\n",
    "\n",
    "# Variable for well sample size\n",
    "num_sample_size = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 500000\n"
     ]
    }
   ],
   "source": [
    "# Calculate budget per well\n",
    "\n",
    "budget_per_well = TOTAL_BUDGET // num_sample_size \n",
    "\n",
    "print(\"$\", budget_per_well) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum volume of oil each well would needs to produce is: 111.1111\n"
     ]
    }
   ],
   "source": [
    "# Finding the amount of units needed from each well to break even\n",
    "\n",
    "average_volume_per_well = budget_per_well / rev_per_unit\n",
    "print(f\"The minimum volume of oil each well would needs to produce is: {round(average_volume_per_well, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0 Average Volume of Predicted Reserve (thousand barrels): 92.5\n",
      "Region 1 Average Volume of Predicted Reserve (thousand barrels): 68.825\n",
      "Region 2 Average Volume of Predicted Reserve (thousand barrels): 95.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate average volumne of predicted reserves\n",
    "\n",
    "average_oil_volume_reg_0 = reg_data_0['product'].mean()\n",
    "average_oil_volume_reg_1 = reg_data_1['product'].mean()\n",
    "average_oil_volume_reg_2 = reg_data_2['product'].mean()\n",
    "\n",
    "print(f\"Region 0 Average Volume of Predicted Reserve (thousand barrels): {round(average_oil_volume_reg_0, 4)}\")\n",
    "print(f\"Region 1 Average Volume of Predicted Reserve (thousand barrels): {round(average_oil_volume_reg_1, 4)}\")\n",
    "print(f\"Region 2 Average Volume of Predicted Reserve (thousand barrels): {round(average_oil_volume_reg_2, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The budget for developing a total of 200 wells is 100 million (100,000,000 USD). This means that the 100 million needs to be distributed among the 200 wells, providing each well with an individual budget of 500,000 uSD. Regardless of which of the three regions the wells are located in, each well has a budget of 500,000 USD.\n",
    "\n",
    "To break even, the 200 wells must collectively produce at least 111.1111 units of material. Any production beyond this amount would generate profit. However, based on the results, none of the regions produce the target volume of 111.1111 units. Here are the average units generated by each region:\n",
    "\n",
    "- Region 0: 92.5 units \n",
    "- Region 1: 68.825 units\n",
    "- Region 2: 95.0 units\n",
    "\n",
    "Since, none of these averages, meet the target of 111.1111 units, meet the threshold value of 111.11 careful selection of the wells is required.\n",
    "- Region 0: 92.5 ≠ 111.1111\n",
    "- Region 1: 68.825 ≠ 111.1111\n",
    "- Region 2: 95.0 ≠ 111.1111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Profit with a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate profit\n",
    "\n",
    "def calculate_profit(region, target, predictions, count):\n",
    "    predictions = pd.Series(predictions)\n",
    "    top_wells = predictions.sort_values(ascending=False).head(count).index\n",
    "    total_reserves = target.reset_index(drop=True).loc[top_wells].sum()\n",
    "    \n",
    "    revenue = total_reserves * REVENUE_PER_UNIT\n",
    "    \n",
    "    profit = revenue - TOTAL_BUDGET\n",
    "    print(f'Region {region} (based on {count} wells)')\n",
    "    print(f'  Volume  : {round(total_reserves, 4)}')\n",
    "    print(f'  Revenue : ${round(revenue, 2)}')\n",
    "    print(f'  Profit  : ${round(profit, 2)}\\n')\n",
    "    \n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0 (based on n=200 wells)\n",
      "  Volume  : 30077.0465\n",
      "  Revenue : $135346709.17\n",
      "  Profit  : $35346709.17\n",
      "\n",
      "Region 1 (based on n=200 wells)\n",
      "  Volume  : 27589.0815\n",
      "  Revenue : $124150866.97\n",
      "  Profit  : $24150866.97\n",
      "\n",
      "Region 2 (based on n=200 wells)\n",
      "  Volume  : 27489.653\n",
      "  Revenue : $123703438.63\n",
      "  Profit  : $23703438.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate profit for each region\n",
    "\n",
    "revenue_final_reg_0 = calculate_profit(\"0\", target_0_valid, predictions_0_valid, 200)\n",
    "revenue_final_reg_1 = calculate_profit(\"1\", target_1_valid, predictions_1_valid, 200)\n",
    "revenue_final_reg_2 = calculate_profit(\"2\", target_2_valid, predictions_2_valid, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0 has highest the profit\n"
     ]
    }
   ],
   "source": [
    "# Find region with largest profit\n",
    "highest_profit = max(revenue_final_reg_0, revenue_final_reg_1, revenue_final_reg_2)\n",
    "\n",
    "if highest_profit == revenue_final_reg_0:\n",
    "    print(\"Region 0 has highest the profit\")\n",
    "elif highest_profit == revenue_final_reg_1:\n",
    "    print(\"Region 1 has highest the profit\")\n",
    "elif highest_profit == revenue_final_reg_2:\n",
    "    print(\"Region 2 has highest the profit\")\n",
    "else: \n",
    "    print(\"Max value did not match a value of any of the three regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Based on the current data, the model predicts that **Region 0** will yield the greatest profit from the 200 wells. After accounting for the initial budget of 100,000,000 USD, Region 0 is projected to generate a profit of 35,346,709.17 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Risk and Profit for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
